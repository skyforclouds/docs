---
title: 'DSL Syntax'
description: 'Keywords and structure for writing model deployment recipes using SoraNova DSL'
icon: 'code'
---

## Variable Declaration

Variables allow you to specify configurable values when deploying a service. If no value is provided during deployment, the variable will use its defined default value.

```hcl
variable "memory_mib" {
  type        = number
  description = "Memory allocation in MiB for the model task"
  default     = 14360
}
```

| Keyword       | Purpose                                                      |
| ------------- | ------------------------------------------------------------ |
| `variable`    | Declares a reusable value block                              |
| `type`        | Specifies the type (`number`, `string`, `list`, etc.)        |
| `description` | Describes what this variable is used for                     |
| `default`     | Provides a fallback value if none is given at deploy time    |

<Tip>
Reference variables with `${var.variable_name}` in your task or resource definitions.
</Tip>

---

## Application Block

The `application` block is the top-level definition for an application deployment. It describes the overall app and contains one or more `service` blocks.

```hcl
application {
  name        = "My Custom Model"
  summary     = "https://huggingface.co/your-company/model"
  description = "A custom model deployment"
  category    = "model"
  tags        = ["llm", "text2text"]

  service "model" {
    name = "my-model"
    // ...service definition...
  }

  service "ui" {
    name = "frontend"
    // ...service definition...
  }
}
```

| Keyword       | Purpose                                                      |
| ------------- | ------------------------------------------------------------ |
| `name`        | Human-readable name for your application                     |
| `summary`     | Link to model card or documentation (optional)               |
| `description` | A short description of your deployment                       |
| `category`    | Category for grouping (e.g., `model`, `agent`, `tool`)       |
| `tags`        | List of tags for search and filtering                        |
| `service`     | Defines a component of your application (model, UI, etc.)    |

Each `service` block describes a deployable component (such as a model backend, UI, or internal service) and can contain nested `task_group` and `task` blocks for detailed configuration.

---

## Service Block

A `service` block defines a deployable component of your application, such as a model backend, UI, or internal service. Each service can contain one or more `task_group` blocks, which in turn contain `task` blocks for detailed configuration.

```hcl
service "model" {
  name = "my-model"

  task_group "model" {
    name  = "my-model"
    count = 1

    task {
      name   = "my-model"
      driver = "docker"
      config {
        image = "my-model-image:latest"
      }
      endpoint api {
        port = 5000
      }
      resources {
        cpu_mhz    = 10240
        memory_mib = 4096
      }
    }
  }
}
```

| Keyword         | Purpose                                                      |
| --------------- | ------------------------------------------------------------ |
| `service`       | Declares a service component (e.g., model, ui, internal)     |
| `name`          | Name of the service instance                                 |
| `uses`          | (Optional) Reference to another service by name              |
| `task_group`    | Defines a group of tasks for this service                    |
| `config`        | (Optional) Service-level configuration (e.g., dependencies)  |

Each `task_group` block can contain one or more `task` blocks, which define how containers or processes are run. Services can also include dependencies and environment variables as needed.

---

## Model Block

The `model` block provides a simplified way to deploy a model.

```hcl
model {
  name  = "llama-8b"
  
  config {
    image = "sglang_hf_generic:latest"
    args  = [
      "--model-path", "meta-llama/Llama-3.1-8B-Instruct",
      "--host", "0.0.0.0",
      "--port", "5000"
    ]
  }

  endpoint llm {
    port = 5000
    health {
      type     = "http"
      path     = "/health"
      interval = "10s"
      timeout  = "2s"
    }
  }

  resources {
    cpu_mhz          = 10240
    memory_mib       = 14360
    sharing_strategy = "${var.sharing_strategy}"
    device {
      name        = "${var.gpu_name}"
      memory_mibs = "${var.gpu_memory_mibs}"
    }
  }
}
```

| Keyword    | Purpose                                                          |
| ---------- | ---------------------------------------------------------------- |
| `name`     | Unique identifier for your model deployment                       |
| `count`    | Number of model replicas to run                                  |
| `config`   | Container configuration including image and startup arguments     |
| `args`     | List of arguments passed to the container                        |
| `endpoint` | Network endpoint and health check configuration                   |
| `resources`| Hardware resource allocation for the model                        |


---

## Config

Configure how your model container should be launched.

```hcl
config {
  image    = "your-custom-model-image:latest"
  args     = ["--host", "0.0.0.0", "--port", "5000"]
}
```

| Keyword     | Purpose                                               |
| ----------- | ----------------------------------------------------- |
| `image`     | Docker image to launch                                |
| `args`      | Command-line arguments passed to your container       |

---

## Endpoint & Health Check

Specify the modelâ€™s serving port and health check mechanism.

```hcl
endpoint llm {
  port = 5000

  health {
    type     = "http"
    path     = "/health"
    interval = "10s"
    timeout  = "2s"
  }
}
```

| Keyword    | Purpose                                                   |
| ---------- | --------------------------------------------------------- |
| `endpoint` | Exposes a port for requests and defines health checks     |
| `port`     | Port that the model will serve traffic on                 |
| `health`   | Block that determines if the container is "healthy"       |
| `type`     | Health check type (`http`)                                |
| `path`     | HTTP path to hit for health checking                      |
| `interval` | How often to check the health                             |
| `timeout`  | Timeout for each health check attempt                     |

<Warning>
  Ensure the health check path is correctly implemented in your model.
  If the health check fails, the model may not be marked as healthy.
</Warning>

---

## Resources and GPU Allocation

Declare CPU, memory, and GPU resources for your task.

```hcl
resources {
  cpu_mhz          = 10240
  memory_mib       = "${var.memory_mib}"
  sharing_strategy = "${var.sharing_strategy}"

  device {
    name        = "${var.gpu_name}"
    memory_mibs = "${var.gpu_memory_mibs}"
  }
}
```

| Keyword           | Purpose                                                  |
| ----------------- | -------------------------------------------------------- |
| `cpu_mhz`         | How much CPU to allocate (in MHz)                        |
| `memory_mib`      | RAM allocated to this task                               |
| `sharing_strategy`| GPU usage model (`mps` for CUDA Multi-Process Service)   |
| `device`          | GPU allocation block                                     |
| `name`            | GPU device name (e.g., `nvidia/gpu`)                     |
| `memory_mibs`     | Memory to allocate per GPU (MiB)                         |

---

## Sample Deployment Flow

```bash
# 1. Seed the model recipe
sora recipe seed model.hcl

# 2. View the available recipes
sora recipe list

# 3. Deploy the model using its slug
sora recipe deploy <recipe-slug>
```
